{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_ML_Regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyDearGreatTeacher/TF/blob/master/TF_ML_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uj3-WVmZG5T",
        "colab_type": "text"
      },
      "source": [
        "https://www.jianshu.com/p/772d57571272\n",
        "\n",
        "比較不同optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2AxAG8IYs0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2040
        },
        "outputId": "01185c3c-43b8-4f7c-ea7a-8b7b761c202d"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 隨機生成1000個點\n",
        "num_points = 1000\n",
        "vectors_set = []\n",
        "for i in range(num_points):\n",
        "    x1 = np.random.normal(0.0, 1)\n",
        "    y1 = x1 * 0.1 + 0.3 + np.random.normal(0.0, 0.01)\n",
        "    vectors_set.append([x1, y1])\n",
        "\n",
        "\n",
        "# 生成一些樣本\n",
        "x_data = [v[0] for v in vectors_set]\n",
        "y_data = [v[1] for v in vectors_set]\n",
        "\n",
        "# 畫出圖像\n",
        "plt.scatter(x_data, y_data, c='r')\n",
        "plt.show()\n",
        "\n",
        "# 初始化參數\n",
        "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0), name='W')\n",
        "b = tf.Variable(tf.zeros([1]), name='b')\n",
        "# 求線性函數\n",
        "y = W * x_data + b\n",
        "\n",
        "# 求損失函數\n",
        "loss = tf.reduce_mean(tf.square(y-y_data), name='loss')\n",
        "# 梯度下降\n",
        "optimizer = tf.train.AdamOptimizer(0.2)\n",
        "train = optimizer.minimize(loss, name='train')\n",
        "\n",
        "# 反覆運算最小化損失值求結果\n",
        "with tf.Session() as sess:\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "    for step in range(100):\n",
        "        sess.run(train)\n",
        "        print('W=', sess.run(W), 'b=', sess.run(b), 'loss=', sess.run(loss))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGblJREFUeJzt3X+MHOd93/H3h0fSMSmrgY5XwCWp\npRDTRZjUSIqr2iBFYCRyS7cFmSJ1IeXOoK20FMkIYZH+iFAWCqrggDgG0hCFJJuwKcjipopitwWL\nMlASx0XaAnJ5SlU3pCKXYHkUhaI+UVZcioj569s/ZsdcLndvZ+/mx87s5wUQdzs72nkWsj989Mx3\nvo8iAjMza5Z1VQ/AzMzy53A3M2sgh7uZWQM53M3MGsjhbmbWQA53M7MGcribmTWQw93MrIEc7mZm\nDbS+qgtv2bIlduzYUdXlzcxq6dVXX307ImaGnVdZuO/YsYPFxcWqLm9mVkuSlrKc52UZM7MGcrib\nmTWQw93MrIEc7mZmDeRwNzNrIIe7mVkDOdzNzBrI4W5m1kAOdzOzBnK4m5kVpd2GHTtg3brkZ7td\n2qUzhbuk3ZLekHRO0hMDzvn7ks5KOiPpN/MdpplZzbTbsH8/LC1BRPJz//7SAl4RsfIJ0hTwTeBj\nwCXgNPBIRJztOmcn8BLwkxHxbUl/PiK+tdLnzs7OhnvLmFlj7diRBHqvVgsuXFj1x0p6NSJmh52X\nZeb+IHAuIs5HxDXgRWBvzzn/EHg6Ir4NMCzYzcwa7+LF0Y7nLEu4bwXe7Hp9qXOs24eBD0v6r5Je\nkbQ7rwGamdXSfff1Px5Ryvp7Xi1/1wM7gY8C24A/lPSXIuLd7pMk7Qf2A9x///05XdrMbMy02/Cd\n7wx+P11/B5ibK2QIWWbubwHbu15v6xzrdgk4GRHXI+J/k6zR7+z9oIg4FhGzETE7MzO017yZWb2k\n1THz83D9+srnXr0KR44UNpQs4X4a2CnpAUkbgYeBkz3n/HuSWTuStpAs05zPcZxmZuOt3YZPf7r/\nTdRBClx/HxruEXEDeBx4GXgdeCkizkh6StKezmkvA5clnQW+BvzTiLhc1KDNzCrXW8P+2GPDZ+u9\nClyeHloKWRSXQppZbaU17Fevrv4zNm2CY8dGXnPPsxTSzMy6HTkyWrC3WnDwYPJTSn6uIthHUdkG\n2WZmtTXKWvn09JoeWlotz9zNzEaVda1840Y4erTYsQzgcDczG9XCQrJm3m3TpruXXo4fL3TpZSUO\ndzOzQQZ1dZybS9bMe9fQn3kmWYK5dSv5WVGwg9fczcz6662I6X2qNP0zpjxzNzPrp19FTMFPlebJ\n4W5m1k/FXR3XyuFuZtbPoIqYmjQ9dLibmfUzqCJmYaGa8YzI4W5mkyfL3qaDKmLG+CZqN1fLmNlk\nGVYF023MK2JW4pm7mU2WmlfBZOVwN7PmOnQI1q9PllXWr09e17wKJiuHu5k1Q+86+kMPwbPPws2b\nyfs3byavB7U5r0kVTFZeczez+uu3jj7KjkgbNtSmCiYrz9zNrJ66Z+r79q1t44zr15M1935VMzXl\nmbuZ1U/vTD1delmLlapmasgzdzOrn1F3QsqqQVUzDnczq58iK1saUjXjcDez+llLZYtU3GePkUzh\nLmm3pDcknZP0RJ/3PyVpWdJrnT//IP+hmpl1LCwkFS6rFQEnTtS6d8wwQ8Nd0hTwNPBxYBfwiKRd\nfU79rYj4kc6fL+Q8TjOz2xUyn/wk3Lixus9IZ+Y17x0zTJZqmQeBcxFxHkDSi8Be4GyRAzOzCddu\nJzc3l5ZgaiqpiJEGP4SURe/MvMa9Y4bJsiyzFXiz6/WlzrFePyPpG5K+LGl7LqMzs8mSzsylZHae\nPoiUljquJdinpxs1Mx8mrxuq/wHYEREfAX4PeL7fSZL2S1qUtLi8vJzTpc2sEdLa9TTQVxvk09Nw\n8OCdyy0nTsDbb09MsEO2ZZm3gO6Z+LbOse+JiMtdL78A/Fq/D4qIY8AxgNnZ2TX8FWxmjZNH7fr0\ndBLilmnmfhrYKekBSRuBh4GT3SdI+mDXyz3A6/kN0cwaqbfR1yi9YPrZsAGOHs1jZI0wdOYeETck\nPQ68DEwBxyPijKSngMWIOAn8gqQ9wA3gHeBTBY7ZzOqq3YbDh+Hy5TuPrzXYAe69d6KWXYZRrOUG\nxRrMzs7G4uJiJdc2swq02/Doo3Dt2uo/Y3r67r8YUhLcurX6z64JSa9GxOyw8/yEqpkVK11+mZ9f\nW7AD3HNPcoO0n4Y8WZoXh7uZFae3AmatlpaSOvUGP1maF4e7mRWniO6NR44k/dsb+mRpXhzuZpav\n7iqYvGbs3ZaW4Pnnk5n6rVtw4YKDvQ+Hu5nlp3sZpshijQb1XS+Kw93M1ibP7e7g9hOmvevqvRrS\nd70oDnczW73emXoe290BPPPM7Y6Ng7g6ZkUOdzNbvSJumKZ17HNzyXp6w/uuF8Xhbmajabdhy5ak\nUqWIG6a9Gt53vShZGoeZmQ1uHZC36em7jzW473pRPHM3s8F6+6sXHewbN7r5V04c7mbWX1791bNI\nl1uOH/cMPSdeljGz/oq4WdqPe7AXwjN3M7tbu13OzVIvwxTG4W42iXo3yjh06PbrLVvg058u7trd\nVS9ehimMl2XMJk26lp4uuSwtwbPP3n6/6JumFy4U+/kGeOZuNnnKWkvvp1+ZoxXC4W42aarqyeI9\nTkvlcDebNPfdV961Nm++vb7+3HNeXy+Rw92s6Xpvnl65Uvw1paSz45Ur7rleEYe7WZP0q4Lp7tq4\ntATf/W5+15OSn9PTyZ90lv7CC0lnR6tMpnCXtFvSG5LOSXpihfN+RlJIGrozt5nlrLf97tISfO5z\n+d88le4M8YjkIaS33/YsfYwMLYWUNAU8DXwMuASclnQyIs72nPcB4DDw9SIGamZD9KuCKaplwK1b\nxXyu5SbLzP1B4FxEnI+Ia8CLwN4+5/0K8Bngz3Icn5kN0t16t6z2u+BNMmoiS7hvBd7sen2pc+x7\nJP1lYHtE/Mccx2Zmg7TbMD9f/ANH/XiTjFpY8w1VSeuAXwf+cYZz90talLS4vLy81kubTa7HHqvm\nups3ez29JrKE+1vA9q7X2zrHUh8Afhj4T5IuAH8NONnvpmpEHIuI2YiYnZmZWf2ozSZZuw3vvVfN\ntat6stVGliXcTwM7JT0gaSPwMHAyfTMi/jQitkTEjojYAbwC7ImIxUJGbDbJ2u1im3oN4/X22hga\n7hFxA3gceBl4HXgpIs5IekrSnqIHaGYd7Tbs2wfXr1dzfW9KXSuZukJGxCngVM+xJwec+9G1D8vM\n7pDO2G/eLOd6UlJGOTWVXLPVSoLd6+214Za/ZuMurYwpW5Hb6lnh3H7AbJx0b0i9bl3ys4pg99p6\n7XnmbjYuejfRqGrm7LX1RvDM3WxcHD5cfalhqwXHjnltvQEc7mbjoN0u52nTVitpxbtp053HN22C\nEyfc9KtBvCxjVqV2O2n4VXRfGOnOZl8//uPJdS9eTNbXXQnTOA53s7KVFejdem+Qzs05zBvOyzJm\nReveQGPLlqRevcxgl3yDdAJ55m5WhO7ZefpAEFTTxfHAAc/SJ5DD3Sxv41LSOD0NR4862CeUw90s\nb/12RCrDxo1w/LjD3ACvuZvl7+LF8q85Pe1gtzs43M3ydt995VxHSmrW0w2qHezWxeFulrd33y3+\nGlNTSaifOpWs8Zv1cLibrUV3o6/165OfRbbllZK19fQaS0vJzVsHvPVwuJutRrud1KzPz9+uWS+6\n13qrlSz5XLt25/GrV5ObuGZdXC1jNqp2Gx599O6QLdL0dNL3Zd2A+VgVN3FtrHnmbjZM9xOmO3bA\nY4+VG+zdBvVZd/916+FwN+s1qF1ARPLzvffKH9M77yQ/Fxb6d3R0ewHr4XA365Y+XZqG+eXL5W1I\nLcHmzf3fS2fmc3NJv/VWKznf/ddtAK+5m3Wr6unSdANquLN1Adw9M3dHR8sgU7hL2g0cBaaAL0TE\nr/a8fwD4eeAmcAXYHxFncx6rWfGquDHZaiU3S7u517qtkWJIUyNJU8A3gY8Bl4DTwCPd4S3p3oj4\nTuf3PcChiNi90ufOzs7G4uLiGodvlrMtW8rt3Lhpk5dVbCSSXo2I2WHnZVlzfxA4FxHnI+Ia8CKw\nt/uENNg7NgMVtcEzW4W0Zl0qN9i9Xm4FyrIssxV4s+v1JeCv9p4k6eeBXwQ2Aj+Zy+jMitRuJ5tS\nlxnoBw/CM8+Udz2bWLlVy0TE0xHxA8AvAf+i3zmS9ktalLS4vLyc16XNRpc+iFT25hkOditJlnB/\nC9je9Xpb59ggLwI/3e+NiDgWEbMRMTszM5N9lGZ56F5+mZ8v/0GkVqvc69lEyxLup4Gdkh6QtBF4\nGDjZfYKknV0v/zbwv/IbolkOqpqpp/ygkZVs6Jp7RNyQ9DjwMkkp5PGIOCPpKWAxIk4Cj0t6CLgO\nfBvYV+SgzUZ2+HD5M/WpKbh1y+WMVolMde4RcQo41XPsya7fD+c8LrP8tNvlz9g3bIDnnnOgW2Xc\nfsCap7fR14ED5V5/3ToHu1XO7QesWdLeMOnj+2mv9bL4oSQbE565W/1174Y0P19Ob5jpaThxIvnj\nJl42hjxzt/qq4iEkSAK9O8Ad5jaGHO5WP1WFOiTr6Q5zqwGHu9XLoUPw7LPVXf/WrequbTYCr7lb\nfbTb1QY7+ClTqw2Hu9XHkSPVXt9PmVqNONxt/B06BOvXl1/WuH59UhXjShirIa+523grc419wwa4\n995kM2q3DLCac7jbeCqrIkZKNsJO9zB1mFtDONxtvJRZ5uhAtwZzuNv46G0dUDQHuzWYb6ja+Dhy\npLxgT69n1lAOd6te2hum7GqYixfLvZ5ZibwsY9Uqeymm2/33l39Ns5I43K067Tbs2wc3bxZ7nXXr\n7m4b4AeSrOG8LGPlSh9IStvzFh3sU1PwpS+5Na9NHM/crTjtdnLT8uLFZAlk82Y4e7a86/dunOEw\ntwnicLdiHDoEn/tc8oAQFH+zdPNmeO+9ZKZ+86Zr2G3iOdwtf+32ncFetFYLLlwo51pmNZFpzV3S\nbklvSDon6Yk+7/+ipLOSviHpq5LcF3WSHTlSXrBLvjFq1sfQcJc0BTwNfBzYBTwiaVfPaf8dmI2I\njwBfBn4t74FajZRZP37ggJdezPrIMnN/EDgXEecj4hrwIrC3+4SI+FpEpIXKrwDb8h2m1UoZ9eMS\nHDwIzzxT/LXMaihLuG8F3ux6falzbJCfA35nLYOyGmq3YcuWJHTLeNL0wAEHu9kKcq1zlzQPzAKf\nHfD+fkmLkhaXl5fzvLRVIW0bkNasl7lh9fPPJ9c3s76yhPtbwPau19s6x+4g6SHgCLAnIr7b74Mi\n4lhEzEbE7MzMzGrGa1VIQ3zduuTnoUPJLH1+vvx+MKmrV934y2wFWUohTwM7JT1AEuoPAz/bfYKk\nHwU+D+yOiG/lPkqrTm/vl6Wl6jepTrnxl9lAQ2fuEXEDeBx4GXgdeCkizkh6StKezmmfBe4BflvS\na5JOFjZiK1fZbXhTrVZSTpnuktSPG3+ZDZTpIaaIOAWc6jn2ZNfvD+U8LhsXVcyOe2vXFxbu7hzp\nxl9mK3LjMFvZffeVf82IO2vX5+aSHjFu/GWWmdsP2GCHDpVbAZPqtwwzN+cwNxuBZ+52W3dp49RU\nsTdOp6eTn9Kdx73cYpYLh/uk6i1vfOgh+OQnb5c29m5ukaeDB+Htt5Pllxde8HKLWQEUZTV46jE7\nOxuLi4uVXHviVbm1nVsGmK2JpFcjYnbYeV5zn0RVlDdKySzds3KzUnhZZhKVXd64aZOD3axkDvdJ\nVPTDPxs3JjdMvY5uVhmH+yTovXn6oQ/dXaWSl3Xr4Pjx5IbprVvJDkkOdrPSec296fr1himq2deG\nDfDccw5zszHgmXtTpbP1+flybp62Wg52szHimXsTlV3q6A2qzcaOZ+5117ue3m6XW+roJ0rNxpJn\n7nXWbz19fr7Ya6ZtA955J6m6WVjwUozZGHK411nZDyOdOOEgN6sJL8vUWZkPI01PO9jNasThXmdl\n7UQkwdGj5VzLzHLhcK+zhYXkhmaRJDhwwLN2s5pxuNfZ3Bz82I/l/7np06utVtITxl0czWrHN1Tr\n7NAh+OpX8/3M6elkCcYzdbNa88x93PWrY08dO5btM1qtZGOMiKTiJd0cY3r6zgZfJ04kPWEc7Ga1\nl2mzDkm7gaPAFPCFiPjVnvd/AvgN4CPAwxHx5WGf6c06Muj3pOmGDfC+98GVK9k/xyWMZo2RdbOO\noTN3SVPA08DHgV3AI5J29Zx2EfgU8JujD9UG6lfHfv36aMHuEkaziZRlzf1B4FxEnAeQ9CKwFzib\nnhARFzrvFbjx5gRaax37pk0uYTSbUFnW3LcCb3a9vtQ5ZkVbbR27N8kwm3il3lCVtF/SoqTF5eXl\nMi9dTwsLyRr7KFotb5JhZpnC/S1ge9frbZ1jI4uIYxExGxGzMzMzq/mIZuutjAG4997s/7w7NJpZ\nR5Y199PATkkPkIT6w8DPFjqqSZRHh0cvw5hZx9CZe0TcAB4HXgZeB16KiDOSnpK0B0DSX5F0CfgE\n8HlJZ4ocdGN0z9T37Vtbh8dWy8FuZt+Tac09Ik5FxIcj4gciYqFz7MmIONn5/XREbIuIzRExHRE/\nVOSga2XQQ0jpTH1pKXm46ObN1V/DyzFm1sPtB4rUb6ll//7k97x6sbda3jDDzO7icC9SvwC/ejU5\nnkcNu9fYzWwA95Yp0qAAv3hxbb3Yp6cd7Ga2Iod7kQYFeLr3aJZe7Gn7XUhC3c29zCwDh3uR+gV4\nevNzbi6Zfd9zz+B/Pn0gKe3o6FA3s4wc7nlKK2MkWL8+qVN///vvbKvbvZwyN5e814/kChgzWzXf\nUM1Lb2VMWtp4+XIyW3/hhf6z7kHr8hGepZvZqnnmnpeVShvTCpl+Bq3Lt1r5jMvMJpLDPS/DShsH\nvb/SuryZ2So53Ec16InTYaWNg95Pb6ymW9+5Va+Z5SDTNntFqOU2e/22vUsfJoK73+s9x4FtZmuU\ndZs931AdxUpPnF64cPucpSWYmkpuqro9gJlVwDP3Uaxbl1Sx9JKSenQzs4LltkG2dVnpiVMzszHi\ncB+FK1vMrCYc7qNwZYuZ1YRvqI5qbs5hbmZjzzN3M7MGcribmTWQw93MrIEc7mZmDZQp3CXtlvSG\npHOSnujz/vsk/Vbn/a9L2pH3QFdlUB8YM7OGGxrukqaAp4GPA7uARyTt6jnt54BvR8SHgH8FfCbv\ngY4s7QOztJQ8Vbq0lLx2wJvZBMgyc38QOBcR5yPiGvAisLfnnL3A853fvwz8lNS9+WcFVuoDY2bW\ncFnCfSvwZtfrS51jfc+JiBvAnwID9o8ryaD+6cP6rpuZNUCpN1Ql7Ze0KGlxeXm52Iu5D4yZTbAs\n4f4WsL3r9bbOsb7nSFoP/Dngcu8HRcSxiJiNiNmZmZnVjTgr94ExswmWJdxPAzslPSBpI/AwcLLn\nnJPAvs7vfw/4g6iql3DKfWDMbIIN7S0TETckPQ68DEwBxyPijKSngMWIOAl8EXhB0jngHZK/AKrn\nPjBmNqEyNQ6LiFPAqZ5jT3b9/mfAJ/IdmpmZrVb9nlD1g0lmZkPVq+Vv7wbV6YNJ4OUXM7Mu9Zq5\n+8EkM7NM6hXufjDJzCyTeoW7H0wyM8ukXuHuB5PMzDKpV7j7wSQzs0zqVS0DfjDJzCyDes3czcws\nE4e7mVkDOdzNzBrI4W5m1kAOdzOzBnK4m5k1kMPdzKyBHO5mZg3kcDczayBVtdWppGVgqcRLbgHe\nLvF6RWnC9/B3GA/+DuNh1O/QioiZYSdVFu5lk7QYEbNVj2OtmvA9/B3Gg7/DeCjqO3hZxsysgRzu\nZmYNNEnhfqzqAeSkCd/D32E8+DuMh0K+w8SsuZuZTZJJmrmbmU2MiQp3Sb8i6RuSXpP0u5L+QtVj\nGpWkz0r6k873+HeSvr/qMY1K0icknZF0S1KtKh0k7Zb0hqRzkp6oejyrIem4pG9J+uOqx7JakrZL\n+pqks53/LR2uekyjkvR9kv6bpP/R+Q7/MtfPn6RlGUn3RsR3Or//ArArIg5UPKyRSPobwB9ExA1J\nnwGIiF+qeFgjkfSDwC3g88A/iYjFioeUiaQp4JvAx4BLwGngkYg4W+nARiTpJ4ArwJci4oerHs9q\nSPog8MGI+CNJHwBeBX66Tv8uJAnYHBFXJG0A/gtwOCJeyePzJ2rmngZ7x2agdn+zRcTvRsSNzstX\ngG1Vjmc1IuL1iHij6nGswoPAuYg4HxHXgBeBvRWPaWQR8YfAO1WPYy0i4v9ExB91fv9/wOvA1mpH\nNZpIXOm83ND5k1smTVS4A0hakPQmMAc8WfV41uhR4HeqHsQE2Qq82fX6EjULlCaStAP4UeDr1Y5k\ndJKmJL0GfAv4vYjI7Ts0Ltwl/b6kP+7zZy9ARByJiO1AG3i82tH2N+w7dM45Atwg+R5jJ8t3MFsr\nSfcAXwH+Uc9/mddCRNyMiB8h+S/wByXltky2Pq8PGhcR8VDGU9vAKeCXCxzOqgz7DpI+Bfwd4Kdi\nTG+ajPDvoU7eArZ3vd7WOWYV6KxTfwVoR8S/rXo8axER70r6GrAbyOVGd+Nm7iuRtLPr5V7gT6oa\ny2pJ2g38M2BPRFytejwT5jSwU9IDkjYCDwMnKx7TROrcjPwi8HpE/HrV41kNSTNptZuk95PcqM8t\nkyatWuYrwF8kqdRYAg5ERK1mXpLOAe8DLncOvVLDip+/C/xrYAZ4F3gtIv5mtaPKRtLfAn4DmAKO\nR8RCxUMamaR/A3yUpBvh/wV+OSK+WOmgRiTprwP/GfifJP9/BvjnEXGqulGNRtJHgOdJ/re0Dngp\nIp7K7fMnKdzNzCbFRC3LmJlNCoe7mVkDOdzNzBrI4W5m1kAOdzOzBnK4m5k1kMPdzKyBHO5mZg30\n/wFjDft0raDpswAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "W= [-0.2856635] b= [0.19999988] loss= 0.15862222\n",
            "W= [-0.09212084] b= [0.37636214] loss= 0.040771082\n",
            "W= [0.08521029] b= [0.48529705] loss= 0.03434975\n",
            "W= [0.23158336] b= [0.51020586] loss= 0.06333225\n",
            "W= [0.33274415] b= [0.4765863] loss= 0.087367095\n",
            "W= [0.38398898] b= [0.40996444] loss= 0.09328806\n",
            "W= [0.39119387] b= [0.32900366] loss= 0.084210515\n",
            "W= [0.36456648] b= [0.24981272] loss= 0.06968629\n",
            "W= [0.3142042] b= [0.18734351] loss= 0.05548181\n",
            "W= [0.24899623] b= [0.15227018] loss= 0.041732047\n",
            "W= [0.1768764] b= [0.1475375] loss= 0.028154727\n",
            "W= [0.10517488] b= [0.16938697] loss= 0.017175514\n",
            "W= [0.04060023] b= [0.21066475] loss= 0.012024453\n",
            "W= [-0.01122945] b= [0.2629106] loss= 0.013951365\n",
            "W= [-0.04645962] b= [0.31711915] loss= 0.021167206\n",
            "W= [-0.06343392] b= [0.3644048] loss= 0.029474609\n",
            "W= [-0.06262392] b= [0.39734513] loss= 0.03408967\n",
            "W= [-0.04616942] b= [0.41159564] loss= 0.032057166\n",
            "W= [-0.0173261] b= [0.40661415] loss= 0.023861583\n",
            "W= [0.01998814] b= [0.38512233] loss= 0.013023462\n",
            "W= [0.06152917] b= [0.3520357] loss= 0.00407841\n",
            "W= [0.10301639] b= [0.31351435] loss= 0.00028456026\n",
            "W= [0.14044678] b= [0.27614644] loss= 0.0021715097\n",
            "W= [0.17044592] b= [0.24601132] loss= 0.0075239916\n",
            "W= [0.19059926] b= [0.22761089] loss= 0.012783875\n",
            "W= [0.19967327] b= [0.22304474] loss= 0.015054984\n",
            "W= [0.19766688] b= [0.23180932] loss= 0.013478229\n",
            "W= [0.18570122] b= [0.25119367] loss= 0.009274197\n",
            "W= [0.16580328] b= [0.27696884] loss= 0.0047030393\n",
            "W= [0.14064154] b= [0.30416355] loss= 0.001718502\n",
            "W= [0.11324262] b= [0.3278982] loss= 0.0010593154\n",
            "W= [0.08669362] b= [0.34424376] loss= 0.002166247\n",
            "W= [0.06383235] b= [0.35092935] loss= 0.003809481\n",
            "W= [0.04694698] b= [0.34767228] loss= 0.0049098856\n",
            "W= [0.03752974] b= [0.336056] loss= 0.0050306055\n",
            "W= [0.03613215] b= [0.31906527] loss= 0.0043599117\n",
            "W= [0.04234696] b= [0.30043185] loss= 0.003363754\n",
            "W= [0.0549091] b= [0.28389636] loss= 0.0024270988\n",
            "W= [0.0718874] b= [0.27248478] loss= 0.0017129873\n",
            "W= [0.09093699] b= [0.26794264] loss= 0.0012454131\n",
            "W= [0.10958853] b= [0.27046973] loss= 0.0010418284\n",
            "W= [0.12555051] b= [0.2788073] loss= 0.0011337802\n",
            "W= [0.13699222] b= [0.29061854] loss= 0.0014768884\n",
            "W= [0.14276563] b= [0.30305237] loss= 0.001879536\n",
            "W= [0.14252865] b= [0.3133757] loss= 0.002061933\n",
            "W= [0.13675095] b= [0.3195519] loss= 0.0018311801\n",
            "W= [0.12660761] b= [0.32063776] loss= 0.0012380873\n",
            "W= [0.11378408] b= [0.31690943] loss= 0.00057396526\n",
            "W= [0.10022268] b= [0.30970326] loss= 0.00018685222\n",
            "W= [0.08784386] b= [0.30103257] loss= 0.00024587158\n",
            "W= [0.07827841] b= [0.29307967] loss= 0.0006300119\n",
            "W= [0.07264945] b= [0.2876786] loss= 0.0010237243\n",
            "W= [0.07143828] b= [0.28590703] loss= 0.001143308\n",
            "W= [0.0744539] b= [0.28788212] loss= 0.00092243025\n",
            "W= [0.08090571] b= [0.2928006] loss= 0.00052715634\n",
            "W= [0.08956123] b= [0.29919732] loss= 0.00020926747\n",
            "W= [0.09895919] b= [0.30534682] loss= 0.00012397407\n",
            "W= [0.10764373] b= [0.3097055] loss= 0.00024637603\n",
            "W= [0.11438385] b= [0.31128564] loss= 0.00042794403\n",
            "W= [0.1183446] b= [0.30987012] loss= 0.0005247249\n",
            "W= [0.11918487] b= [0.30602017] loss= 0.0004899859\n",
            "W= [0.11707] b= [0.30088586] loss= 0.00037439904\n",
            "W= [0.11260367] b= [0.295878] loss= 0.00025980812\n",
            "W= [0.10669649] b= [0.2922909] loss= 0.00019524283\n",
            "W= [0.10039776] b= [0.2909738] loss= 0.00018116146\n",
            "W= [0.09471973] b= [0.29213488] loss= 0.00019454276\n",
            "W= [0.09048265] b= [0.295323] loss= 0.00021667975\n",
            "W= [0.08820368] b= [0.2995833] loss= 0.00023843488\n",
            "W= [0.08804387] b= [0.3037359] loss= 0.00025021433\n",
            "W= [0.0898167] b= [0.3066998] loss= 0.00023888773\n",
            "W= [0.09305066] b= [0.30777326] loss= 0.0001996213\n",
            "W= [0.09709051] b= [0.30679825] loss= 0.00014791444\n",
            "W= [0.10121763] b= [0.30416998] loss= 0.00011346354\n",
            "W= [0.1047686] b= [0.30069727] loss= 0.00011687322\n",
            "W= [0.10723407] b= [0.29735973] loss= 0.00015053236\n",
            "W= [0.10832434] b= [0.2950331] loss= 0.00018334128\n",
            "W= [0.10799486] b= [0.29425883] loss= 0.00018646933\n",
            "W= [0.10643129] b= [0.2951196] loss= 0.00015691984\n",
            "W= [0.10400025] b= [0.29724884] loss= 0.00011791919\n",
            "W= [0.10117622] b= [0.29996338] loss= 9.724439e-05\n",
            "W= [0.09845752] b= [0.3024752] loss= 0.00010429788\n",
            "W= [0.09628481] b= [0.30411774] loss= 0.00012567596\n",
            "W= [0.09497437] b= [0.30452222] loss= 0.00014017681\n",
            "W= [0.0946754] b= [0.30369735] loss= 0.00013713614\n",
            "W= [0.09535678] b= [0.3019958] loss= 0.000122049685\n",
            "W= [0.09682382] b= [0.29998505] loss= 0.000107766435\n",
            "W= [0.0987611] b= [0.29826647] loss= 0.00010238092\n",
            "W= [0.10079343] b= [0.29729897] loss= 0.00010486613\n",
            "W= [0.10255421] b= [0.29727846] loss= 0.0001095126\n",
            "W= [0.10374926] b= [0.2981044] loss= 0.00011214809\n",
            "W= [0.10420528] b= [0.29943708] loss= 0.00011206239\n",
            "W= [0.10389459] b= [0.30082142] loss= 0.00011002386\n",
            "W= [0.10293226] b= [0.30183476] loss= 0.000106535015\n",
            "W= [0.10154695] b= [0.30221212] loss= 0.00010234295\n",
            "W= [0.10003158] b= [0.30191216] loss= 9.931931e-05\n",
            "W= [0.09868392] b= [0.30110845] loss= 9.940266e-05\n",
            "W= [0.09774898] b= [0.30011436] loss= 0.000102372316\n",
            "W= [0.09737452] b= [0.29927075] loss= 0.00010536358\n",
            "W= [0.09758803] b= [0.2988347] loss= 0.00010528877\n",
            "W= [0.09829906] b= [0.29890466] loss= 0.000101839\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}